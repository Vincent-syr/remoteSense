{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "from methods import backbone, resnet12\n",
    "from data.datamgr import SetDataManager\n",
    "# from methods.protonet import ProtoNet\n",
    "from methods.protonet_multi_gpu import ProtoNetMulti\n",
    "from loss.nt_xent import NTXentLoss\n",
    "from io_utils import model_dict, parse_args, get_resume_file, get_trlog, save_fig\n",
    "from utils import Timer\n",
    "import argparse\n",
    "from utils import euclidean_dist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alpha=2.0, dataset='NWPU', init_lr=0.001, lr_anneal='const', method='cs_protonet', mlp_dropout=0.7, model='ResNet12', n_episode=100, n_query=8, n_shot=1, num_classes=200, optim='Adam', os='linux', save_freq=10, start_epoch=0, stop_epoch=300, test_n_way=5, train_aug=True, train_n_way=5, warmup=False, wd='0')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset'     , default='CUB',        help='CUB/miniImagenet/cross/omniglot/cross_char')\n",
    "parser.add_argument('--os'          , default='linux',        help='linux/windows')\n",
    "\n",
    "parser.add_argument('--dataset'     , default='NWPU',        help='NPPU/WHU-RS19/UCMERCED')\n",
    "parser.add_argument('--model'       , default='ResNet12',      help='model: Conv{4|6} / ResNet{10|18|34|50|101}') # 50 and 101 are not used in the paper\n",
    "parser.add_argument('--method'      , default='cs_protonet',   help='rotate/baseline/baseline++/protonet/matchingnet/relationnet{_softmax}/maml{_approx}') #relationnet_softmax replace L2 norm with softmax to expedite training, maml_approx use first-order approximation in the gradient for efficiency\n",
    "parser.add_argument('--train_n_way' , default=5, type=int,  help='class num to classify for training') #baseline and baseline++ would ignore this parameter\n",
    "parser.add_argument('--test_n_way'  , default=5, type=int,  help='class num to classify for testing (validation) ') #baseline and baseline++ only use this parameter in finetuning\n",
    "parser.add_argument('--n_shot'      , default=1, type=int,  help='number of labeled data in each class, same as n_support') #baseline and baseline++ only use this parameter in finetuning\n",
    "parser.add_argument('--n_query'      , default=8, type=int,  help='number of unlabeled  query data in each class, same as n_query') #baseline and baseline++ only use this parameter in finetuning\n",
    "\n",
    "parser.add_argument('--train_aug'   , default=True, type=bool, help='perform data augmentation or not during training ') #still required for save_features.py and test.py to find the model path correctly\n",
    "# parser.add_argument('--no_aug' ,dest='train_aug', action='store_false', default=True,  help='perform data augmentation or not during training ') \n",
    "\n",
    "parser.add_argument('--n_episode', default=100, type=int, help = 'num of episodes in each epoch')\n",
    "parser.add_argument('--mlp_dropout' , default=0.7, help='dropout rate in word embedding transformer')\n",
    "# parser.add_argument('--aux'   , default=False,  help='use attribute as auxiliary data, multimodal method')\n",
    "\n",
    "# learning rate, optim\n",
    "parser.add_argument('--lr_anneal', default='const', help='const/pwc/exp, schedule learning rate')\n",
    "parser.add_argument('--init_lr', default=0.001)\n",
    "parser.add_argument('--optim', default='Adam', help='Adam/SGD')\n",
    "parser.add_argument('--wd', default='0', help='weight_decay  /  {0|0.001|...}')\n",
    "parser.add_argument('--alpha'       , default=2.0, type=int, help='for manifold_mixup or S2M2 training ')\n",
    "\n",
    "parser.add_argument('--num_classes' , default=200, type=int, help='total number of classes in softmax, only used in baseline') #make it larger than the maximum label value in base class\n",
    "parser.add_argument('--save_freq'   , default=10, type=int, help='Save frequency')\n",
    "parser.add_argument('--start_epoch' , default=0, type=int,help ='Starting epoch')\n",
    "parser.add_argument('--stop_epoch'  , default=300, type=int, help ='Stopping epoch') #for meta-learning methods, each epoch contains 100 episodes. The default epoch number is dataset dependent. See train.py\n",
    "parser.add_argument('--warmup'      , action='store_true', help='continue from baseline, neglected if resume is true') #never used in the paper\n",
    "\n",
    "\n",
    "\n",
    "params = parser.parse_args([])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alpha=2.0, batch_size=45, checkpoint_dir='checkpoints/NWPU/ResNet12_cs_protonet_aug_Adam_lr0.001_const_wd0_5way_1shot', dataset='NWPU', init_lr=0.001, lr_anneal='const', method='cs_protonet', mlp_dropout=0.7, model='ResNet12', model_dir='checkpoints/NWPU/ResNet12_cs_protonet_aug_Adam_lr0.001_const_wd0_5way_1shot/model', n_episode=100, n_query=8, n_shot=1, num_classes=200, optim='Adam', os='linux', save_freq=10, start_epoch=0, stop_epoch=300, test_n_way=5, train_aug=True, train_n_way=5, warmup=False, wd='0')\n",
      "image_size =  84\n",
      "n_query =  8\n",
      "checkpoint_dir =  checkpoints/NWPU/ResNet12_cs_protonet_aug_Adam_lr0.001_const_wd0_5way_1shot\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "print(params)    \n",
    "\n",
    "# if params.os == 'linux':\n",
    "#     base_file = os.path.join('./filelists', params.dataset, 'base_linux.json')\n",
    "#     val_file = os.path.join('./filelists', params.dataset, 'val_linux.json')\n",
    "# else:\n",
    "base_file = os.path.join('./filelists', params.dataset, ('base_%s.json' % params.os))\n",
    "val_file = os.path.join('./filelists', params.dataset,  ('val_%s.json' % params.os))\n",
    "# novel_file = os.path.join('./filelists', params.dataset, 'novel.json')\n",
    "\n",
    "image_size = 84\n",
    "params.image_size = image_size\n",
    "\n",
    "print('image_size = ', image_size)\n",
    "print(\"n_query = \", params.n_query)\n",
    "params.batch_size = (params.n_query + params.n_shot) * params.train_n_way\n",
    "\n",
    "train_few_shot_params   = dict(n_way = params.train_n_way, n_support = params.n_shot, n_query=params.n_query) \n",
    "base_datamgr            = SetDataManager(image_size, n_episode=params.n_episode, params=params, **train_few_shot_params)\n",
    "base_loader             = base_datamgr.get_data_loader( base_file , aug = params.train_aug )\n",
    "\n",
    "test_few_shot_params     = dict(n_way = params.test_n_way, n_support = params.n_shot, n_query = params.n_query) \n",
    "val_datamgr             = SetDataManager(image_size, n_episode=params.n_episode, params=params, **test_few_shot_params)\n",
    "val_loader              = val_datamgr.get_data_loader(val_file, aug = False) \n",
    "\n",
    "model = ProtoNetMulti(model_dict[params.model], params=params, **train_few_shot_params)\n",
    "model = model.cuda()\n",
    "params.checkpoint_dir = 'checkpoints/%s/%s_%s' %(params.dataset, params.model, params.method)\n",
    "if params.train_aug:\n",
    "    params.checkpoint_dir += '_aug'\n",
    "\n",
    "params.checkpoint_dir += '_%s_lr%s_%s_wd%s' % (params.optim, str(params.init_lr), params.lr_anneal, str(params.wd))\n",
    "\n",
    "if not params.method  in ['baseline', 'baseline++']: \n",
    "    params.checkpoint_dir += '_%dway_%dshot' %( params.train_n_way, params.n_shot)\n",
    "params.model_dir = os.path.join(params.checkpoint_dir, 'model')\n",
    "if not os.path.isdir(params.model_dir):\n",
    "    os.makedirs(params.model_dir)\n",
    "print('checkpoint_dir = ', params.checkpoint_dir)\n",
    "start_epoch = params.start_epoch\n",
    "stop_epoch = params.stop_epoch\n",
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train contrastive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_mlp = nn.Sequential(\n",
    "    nn.Linear(model.feat_dim, model.feat_dim),\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(model.feat_dim, 256)\n",
    ").cuda()\n",
    "\n",
    "cs_criterion = NTXentLoss(params.batch_size).cuda()\n",
    "init_lr = params.init_lr\n",
    "optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},\n",
    "            {'params': cs_mlp.parameters()}\n",
    "    ], lr=init_lr)\n",
    "\n",
    "timer = Timer()\n",
    "print_freq = 50\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup Loss 6.131\n",
      "Mixup Loss 1.741\n",
      "Mixup Loss 2.777\n",
      "Mixup Loss 1.962\n",
      "Mixup Loss 0.613\n",
      "Mixup Loss 1.056\n",
      "Mixup Loss 0.754\n",
      "Mixup Loss 0.773\n",
      "Mixup Loss 0.385\n",
      "Mixup Loss 0.503\n"
     ]
    }
   ],
   "source": [
    "print_freq = 10\n",
    "for i, (x, _) in enumerate(base_loader, 1):\n",
    "   # manifold mixup loss\n",
    "    xi = x[0].cuda()    # n_way * (k_shot+query)\n",
    "    xj = x[1].cuda()    # n_way * (k_shot+query)\n",
    "    # manifold mixup loss\n",
    "    inputs = xi\n",
    "    targets = torch.from_numpy(np.repeat(range(model.n_way), model.n_query)).cuda()\n",
    "    lam = np.random.beta(params.alpha, params.alpha)\n",
    "    # 分割 x_support, x_query\n",
    "    inputs = inputs.view(model.n_way, (model.n_support + model.n_query), 3, params.image_size, params.image_size)\n",
    "\n",
    "    x_support   = inputs[:, :model.n_support]   # (n_way, n_support, )\n",
    "    x_query     = inputs[:, model.n_support:]  \n",
    "    x_support   = x_support.contiguous().view(model.n_way*model.n_support, 3, params.image_size, params.image_size)  # (n_way * n_support) \n",
    "    x_query     = x_query.contiguous().view(model.n_way*model.n_query, 3, params.image_size, params.image_size)  # (n_way * n_query) \n",
    "    # x_support：model forward：得到z_support\n",
    "    z_support = model.forward(x_support)\n",
    "    z_support = z_support.view(model.n_way, model.n_support, -1)\n",
    "    # x_query 计算插值, 得到z_query, target_a, target_b\n",
    "    z_query, target_a , target_b = model.forward(x_query, targets, mixup_hidden= True, lam = lam)  # (n_way * n_query, feat_dim)\n",
    "    img_proto   = z_support.mean(1)   # (n_way, feat_dim)\n",
    "    # 用z_pred，tareget_a, target_b计算loss\n",
    "    dists = euclidean_dist(z_query, img_proto)  # (n_way*n_query, n_way)\n",
    "    scores = -dists\n",
    "    criterion = model.loss_fn\n",
    "    mm_loss = mixup_criterion(criterion, scores, target_a, target_b, lam)\n",
    "\n",
    "    mm_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    cum_mm_loss = mm_loss.item()\n",
    "    avg_mm_loss = cum_mm_loss / float(i)\n",
    "    # train_loss += loss.data.item()\n",
    "    if i % print_freq == 0:\n",
    "        print('Mixup Loss {:.3f}'.format(avg_mm_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 9, 3, 84, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3, 84, 84])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "\n",
    "x_support.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_support   = inputs[:, :model.n_support]   # (n_way, n_support, )\n",
    "x_query     = inputs[:, model.n_support:]  \n",
    "x_support   = x_support.contiguous().view(model.n_way*model.n_support, 3, params.image_size, params.image_size)  # (n_way * n_support) \n",
    "x_query     = x_query.contiguous().view(model.n_way*model.n_query, 3, params.image_size, params.image_size)  # (n_way * n_query) \n",
    "# x_support：model forward：得到z_support\n",
    "z_support = model.forward(x_support)\n",
    "z_support = z_support.view(model.n_way, model.n_support, -1)\n",
    "# x_query 计算插值, 得到z_query, target_a, target_b\n",
    "z_query, target_a , target_b = model.forward(x_query, targets, mixup_hidden= True, lam = lam)\n",
    "img_proto   = z_support.mean(1)   # (n_way, feat_dim)\n",
    "# 用z_pred，tareget_a, target_b计算loss\n",
    "dists = euclidean_dist(z_query, img_proto)  # n_way\n",
    "scores = -dists\n",
    "criterion = model.loss_fn\n",
    "loss = mixup_criterion(criterion, scores, target_a, target_b, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 84, 84])\n",
      "torch.Size([5, 1, 512])\n",
      "torch.Size([40, 512])\n",
      "torch.Size([5, 512])\n",
      "torch.Size([40, 5])\n",
      "tensor(33.5620, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x_support.shape)\n",
    "print(z_support.shape)\n",
    "print(z_query.shape)\n",
    "print(img_proto.shape)\n",
    "print(dists.shape)  # torch.Size([40, 5])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.compute_score(zi)\n",
    "correct_this, count_this = model.correct(scores)\n",
    "y_query = torch.from_numpy(np.repeat(range(model.n_way), model.n_query))\n",
    "y_query = Variable(y_query.long().cuda())\n",
    "clf_loss = model.loss_fn(scores, y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute contrastive loss\n",
    "zics = cs_mlp(zi)\n",
    "zjcs = cs_mlp(zj)\n",
    "cs_loss = cs_criterion(zics, zjcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 40\n",
      "tensor(35.4992, device='cuda:0', grad_fn=<NllLossBackward>) tensor(4.2756, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(correct_this, count_this)\n",
    "print(clf_loss, cs_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 3, 84, 84])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(45,3,84,84)\n",
    "a.shape\n",
    "a = a.view(5, 9, -1, a.shape[-2], a.shape[-1])\n",
    "support = a[:,:1]\n",
    "query = a[:, 1:]\n",
    "support.shape\n",
    "query.shape\n",
    "query.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_s2m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"hello wod\"\n",
    "b = \"llo\"\n",
    "b in a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch140-gpu",
   "language": "python",
   "name": "torch140-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
